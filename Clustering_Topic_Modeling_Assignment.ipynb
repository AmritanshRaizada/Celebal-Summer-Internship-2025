{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d4b202",
   "metadata": {},
   "source": [
    "# Clustering Algorithms for Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78721d7d",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Apply LDA and K-Means to group similar documents and discover topics from text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b1e789",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb916e6",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c80a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "documents = newsgroups.data[:1000]  # Use a subset for performance\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "documents = [preprocess(doc) for doc in documents]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e21dc0",
   "metadata": {},
   "source": [
    "### 3. LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer_lda = CountVectorizer(max_df=0.9, min_df=2, stop_words='english')\n",
    "doc_term_matrix = vectorizer_lda.fit_transform(documents)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(doc_term_matrix)\n",
    "\n",
    "# Display topics\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"\\nTopic #{idx + 1}:\")\n",
    "    print([vectorizer_lda.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fae038",
   "metadata": {},
   "source": [
    "### 4. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec978d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer_kmeans = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer_kmeans.fit_transform(documents)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer_kmeans.get_feature_names_out()\n",
    "\n",
    "# Display cluster keywords\n",
    "for i in range(5):\n",
    "    print(f\"\\nCluster #{i + 1}:\")\n",
    "    print([terms[ind] for ind in order_centroids[i, :10]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77dd459",
   "metadata": {},
   "source": [
    "### 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc5ab8",
   "metadata": {},
   "source": [
    "\n",
    "- **LDA** provides interpretable topics from documents.\n",
    "\n",
    "- **K-Means** clusters documents based on feature similarity.\n",
    "\n",
    "- Both techniques are valuable for understanding large text corpora.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
